{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1590b55-f4df-4962-b993-46d553d45a00",
   "metadata": {},
   "source": [
    "# Dictionary :\n",
    "- Dictionary in python is a collection of keys : values , used to store a data values like a mape , unlike other data types which hold only single item\n",
    "## characteristics :\n",
    "- mutability\n",
    "- indexing has no meaning\n",
    "- keys can't be mutable items\n",
    "- keys can't be duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9e9711-4d11-4342-918e-0edffa799dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Majid', 'f_name': 'Talib Hussain', ' city_name': 'RajanPur', 'semester': 7}\n"
     ]
    }
   ],
   "source": [
    "# 1D dictionary :\n",
    "dict = {\n",
    "    'name' : 'Majid',\n",
    "    'f_name' : 'Talib Hussain',\n",
    "    ' city_name' : 'RajanPur' ,\n",
    "     'semester' : 7 \n",
    "}\n",
    "print(dict)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61a212ea-9950-4c28-804c-f1c4118d7ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'f_name', ' city_name', 'semester'])\n"
     ]
    }
   ],
   "source": [
    "# 1D dictionary :\n",
    "dict = {\n",
    "    'name' : 'Majid',\n",
    "    'f_name' : 'Talib Hussain',\n",
    "    ' city_name' : 'RajanPur' ,\n",
    "     'semester' : 7 \n",
    "}\n",
    "print(dict.keys())\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4313736b-0926-446d-84a8-3818617af93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Majid', 'Talib Hussain', 'RajanPur', 7])\n"
     ]
    }
   ],
   "source": [
    "# 1D dictionary :\n",
    "dict = {\n",
    "    'name' : 'Majid',\n",
    "    'f_name' : 'Talib Hussain',\n",
    "    ' city_name' : 'RajanPur' ,\n",
    "     'semester' : 7 \n",
    "}\n",
    "print(dict.values())\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0b50545-d8ed-4519-91b5-07236bb35492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'name': 'Majid_Hussain', 'F_name': 'Talib Hussain', 'Roll_no': 1149, 'class_section': '3M(C)', 'year_of_study': 2022, 'U_name': 'The IUB', 'CGPA': 3.6, 'Sem.': '7th', 'subject': {'graph_Theory': 100, 'TTD': 200, 'Web_development': 200}, 22: 2026, 2.7: 3.6, 'In_library': True}\n"
     ]
    }
   ],
   "source": [
    "studentData={\n",
    "    # Key      :     value\n",
    "    \n",
    "    \"name\": \"Majid_Hussain\",\n",
    "    \"F_name\": \"Talib Hussain\",\n",
    "    \"Roll_no\": 1149,\n",
    "    \"class_section\": \"3M(C)\",\n",
    "    \"year_of_study\": 2022,\n",
    "    \"U_name\": \"The IUB\",\n",
    "    \"CGPA\": 3.6,\n",
    "    \"Sem.\": \"7th\",\n",
    "    \"subject\" : {\n",
    "        \"graph_Theory\" : 100,\n",
    "        \"TTD\" : 200,\n",
    "        \"Web_development\" : 200\n",
    "    },\n",
    "    22: 2026,\n",
    "    2.7: 3.6,\n",
    "    \"In_library\": True,\n",
    "    \n",
    "# writing of last two lines it means dictionary can store of bolean and float values like tuples here we can change the value of dictionary\n",
    "}\n",
    "print(type(studentData))\n",
    "print(studentData)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903017c-7460-4d85-913a-fda688a33af6",
   "metadata": {},
   "source": [
    "## Accessing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca22601-fde1-4f01-86fb-9ec59432450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiveth\n",
      "Majid_Hussain\n",
      "Talib Hussain\n"
     ]
    }
   ],
   "source": [
    "print(studentData[\"Sem.\"])\n",
    "print(studentData[\"name\"])\n",
    "print(studentData[\"F_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01057b3d-f282-4e90-ab22-5cc506aa42ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'F_name': 'Talib Hussain', 'Roll_no': 1149, 'class_section': '3M(C)', 'year_of_study': 2022, 'U_name': 'The IUB', 'CGPA': 3.6, 'Sem.': '7th', 'subject': {'graph_Theory': 100, 'TTD': 200, 'Web_development': 200}, 22: 2026, 2.7: 3.6, 'In_library': True}\n"
     ]
    }
   ],
   "source": [
    "# Is this mutable we can check \n",
    "studentData[\"name\"]= \"Amir Khan\"\n",
    "print(studentData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2198f3e5-9b4f-4a08-8271-561e0425857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'F_name': 'Talib Hussain', 'Roll_no': 1149, 'class_section': '3M(C)', 'year_of_study': 2022, 'U_name': 'The IUB', 'CGPA': 3.6, 'Sem.': '7th', 'subject': {'graph_Theory': 100, 'TTD': 200, 'Web_development': 200}, 22: 2026, 2.7: 3.6, 'In_library': True, 'New_Data': {'subject': ['Math', 'Statistics', 'probability'], 'topics': ['leaner', 'derivative', 'Intergration']}}\n"
     ]
    }
   ],
   "source": [
    "# Here we can create new empty dictionary in which we passed our new values\n",
    "studentData[\"New_Data\"] ={\n",
    "    \"subject\": [\"Math\", \"Statistics\", \"probability\"],\n",
    "    \"topics\": [\"leaner\", \"derivative\", \"Intergration\"]\n",
    "}\n",
    "print(studentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b1a5fe2-8204-45d8-8e1b-ea024a0483d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Math', 'Statistics', 'probability']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can access nested dictionary by using of \n",
    "studentData['New_Data']['subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a3491d-ecb4-45a0-9bea-87d753323104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}}\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "# Nested dictionary in which another dictionary if we need any specific data from student like any subject or many more data we can use key\n",
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student)\n",
    "print(Student[ \"subject\"]['physics'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0d91a-c926-4031-812e-2ad442ebd323",
   "metadata": {},
   "source": [
    "# Dictionary operations :\n",
    "- keys()/ values()/ items()/ del or pop() or popitem()/ clear() / get()/ update() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11f36e2d-981c-4bb5-a4f3-0c509922016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'R_No', 'subject'])\n",
      "dict_values(['Amir Khan', 1149, {'physics': 74, 'Math': 44, 'computer': 53}])\n",
      "dict_items([('name', 'Amir Khan'), ('R_No', 1149), ('subject', {'physics': 74, 'Math': 44, 'computer': 53})])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary method here we can use any method like list method, tuples method , remove , pop, add, etc....\n",
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student.keys())    # return all the keys \n",
    "print(Student.values())   # return all values\n",
    "print(Student.items())# Return all (keys: values) with pairs of tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a80943-7758-43a0-b556-ab32caa4632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('name', 'Amir Khan'), ('R_No', 1149), ('subject', {'physics': 74, 'Math': 44, 'computer': 53})])\n",
      "('subject', {'physics': 74, 'Math': 44, 'computer': 53})\n",
      "{'physics': 74, 'Math': 44, 'computer': 53}\n"
     ]
    }
   ],
   "source": [
    "# to access the method of items in dictionary\n",
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student.items())\n",
    "\n",
    "#Here is used to access specific key:value according to index \n",
    "pair=list(Student.items())\n",
    "print(pair[2])\n",
    "\n",
    "#Another method to access value according to index this method is very useful i recomended to use this method\n",
    "print(Student[\"subject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c058821-7a13-4606-9214-bb5a4d8ac634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}}\n",
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}, 'city': 'RajanPur'}\n"
     ]
    }
   ],
   "source": [
    "# Here we are using updating method to add new value at the end in old dictionary to update\n",
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student)\n",
    "Student.update({\"city\" : \"RajanPur\"})\n",
    "print(Student)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e65c9cb5-5d02-44d2-9424-25e65ff42c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}}\n",
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}, 'city': 'RajanPur'}\n"
     ]
    }
   ],
   "source": [
    "# Here we are using updating method to add new value at the end in old dictionary to update \n",
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student)\n",
    "Student['city'] = 'RajanPur'\n",
    "print(Student)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93f23d0-c77a-429e-b655-2252c9212c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53, 'City': 'RajanPur'}}\n",
      "1149\n"
     ]
    }
   ],
   "source": [
    "# But by using of this method we just add any value in specific dictionary items\n",
    "# There are two methods to update or add new value one above this code and one is this\n",
    "\n",
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "# print(Student)\n",
    "Student[\"subject\"][\"City\"] = \"RajanPur\"              #This is just temporary addition\n",
    "print(Student)\n",
    "print(Student.get(\"R_No\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44cbe40d-d552-4604-82c0-5fe206e9e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}}\n",
      "dict_keys(['name', 'R_No', 'subject'])\n",
      "dict_values(['Amir Khan', 1149, {'physics': 74, 'Math': 44, 'computer': 53}])\n",
      "Amir Khan\n",
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}, 'city': 'Rajanpur'}\n",
      "dict_items([('name', 'Amir Khan'), ('R_No', 1149), ('subject', {'physics': 74, 'Math': 44, 'computer': 53}), ('city', 'Rajanpur')])\n"
     ]
    }
   ],
   "source": [
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student)\n",
    "print(Student.keys())\n",
    "print(Student.values())\n",
    "print(Student.get(\"name\"))\n",
    "Student.update({\"city\":\"Rajanpur\"})\n",
    "print(Student)\n",
    "print(Student.items())\n",
    "# print(Student.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee65cb8-654a-43e6-b1d7-b8daeff3fa24",
   "metadata": {},
   "source": [
    "# Advance level :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "716b15b0-42b9-4263-b85b-14e482d2e169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}}\n",
      "{'name': 'Amjad Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53, 'Brother_name': 'Amir Khan'}, 'sblings': {'Brother_name': 'Amir khan', 'Younger_brother': 'Amjad khan'}, 'city': 'shikarPur'}\n"
     ]
    }
   ],
   "source": [
    "Student={\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(Student)\n",
    "\n",
    "# Adding of nested dictionary inside of existing dictionary\n",
    "Student[\"sblings\"] = {\n",
    "    \"Brother_name\" : \"Amir khan\",\n",
    "    \"Younger_brother\" : \"Amjad khan\"\n",
    "}\n",
    "\n",
    "Student[\"name\"] = \"Amjad Khan\"    # this modifying in dictionary to change \n",
    "Student[\"city\"] = \"shikarPur\"     # It is adding at the end of dictionary\n",
    "Student[\"subject\"][\"Brother_name\"] = \"Amir Khan\"    # by adding inside of nested dictionary this method would be better\n",
    "print(Student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca6767e8-ae16-4af4-95f6-2bf05019ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Amir Khan', 'R_No': 1149, 'subject': {'physics': 74, 'Math': 44, 'computer': 53}}\n",
      "keys of dictionary:\n",
      "{'name'}\n",
      "{'R_No'}\n",
      "{'subject'}\n"
     ]
    }
   ],
   "source": [
    "# Iterate through keys  \n",
    "my_dict = {\n",
    "    \"name\": \"Amir Khan\",\n",
    "    \"R_No\": 1149,\n",
    "    \n",
    "    \"subject\" :{ \n",
    "    \"physics\": 74,\n",
    "    \"Math\": 44,\n",
    "    \"computer\": 53\n",
    "}\n",
    "}\n",
    "print(my_dict)\n",
    "print('keys of dictionary:')  \n",
    "for key in my_dict.keys():  \n",
    "    print({key})  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58313c13-6afa-4687-a56d-1557c15576d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Values of dictionary:\n",
      "Amir Khan\n",
      "1149\n",
      "{'physics': 74, 'Math': 44, 'computer': 53}\n"
     ]
    }
   ],
   "source": [
    "# Iterate through values  \n",
    "print('\\nValues of dictionary:')  \n",
    "for value in my_dict.values():  \n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea8160c-f610-479a-bbe9-407ea1709bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys and and values pair:\n",
      "name Amir Khan\n",
      "R_No 1149\n",
      "subject {'physics': 74, 'Math': 44, 'computer': 53}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Iterate through key-value pairs \n",
    "print('\\nKeys and and values pair:')\n",
    "for key, value in my_dict.items(): \n",
    "    print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b707d402-1cb8-4895-a47b-3992b6b5c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie\n",
      "IL\n"
     ]
    }
   ],
   "source": [
    "nested_dict = {  \n",
    "    \"person\": {  \n",
    "        \"name\": \"Charlie\",  \n",
    "        \"age\": 35  \n",
    "    },  \n",
    "    \"location\": {  \n",
    "        \"city\": \"Chicago\",  \n",
    "        \"state\": \"IL\"  \n",
    "    }  \n",
    "}  \n",
    "\n",
    "print(nested_dict[\"person\"][\"name\"]) \n",
    "print(nested_dict[\"location\"][\"state\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c39befb-45bd-42db-8389-440952e54b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 8, 3: 27, 4: 64}\n"
     ]
    }
   ],
   "source": [
    "cubes = {x:x**3 for x in range(5)}\n",
    "print(cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be5766d-3a6d-498e-9afd-812837d082a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"user1\": {\"age\": 25, \"income\": 50000, \"label\": \"positive\"},\n",
    "    \"user2\": {\"age\": 30, \"income\": 60000, \"label\": \"negative\"}\n",
    "}\n",
    "print(dataset[\"user1\"][\"age\"]) \n",
    "print(dataset[\"user2\"]['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf43f39-ea57-4585-b711-22bb0aa9b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'python': 2, 'is': 2, 'easy': 1, 'to': 1, 'learn': 1, 'because': 1, 'fun': 1})\n"
     ]
    }
   ],
   "source": [
    "text = \"python is easy to learn because python is fun\".split()\n",
    "freq = Counter(text)\n",
    "print(freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1f2655-5bb5-4732-9f06-b136a6137043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('python', 2), ('is', 2)]\n"
     ]
    }
   ],
   "source": [
    "text = \"python is easy to learn because python is fun\".split()\n",
    "most_com = Counter(text)\n",
    "print(most_com.most_common(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54443e50-6908-4939-b959-44012f5e9408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 3, 'n': 2, 'b': 1})\n"
     ]
    }
   ],
   "source": [
    "text = \"banana\"\n",
    "freq = Counter(text)\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28eec2d1-2667-4000-a191-d48f2565e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates value in theis list are: ['pen', 'bag']\n"
     ]
    }
   ],
   "source": [
    "# find duplicates from list comprehension\n",
    "\n",
    "text = ['pen', 'book', 'pen', 'bag', 'bag', 'bag']\n",
    "freqe = Counter(text)\n",
    "duplicates = [item for item, freq in freqe.items() if freq>1]\n",
    "print(f'Duplicates value in theis list are: {duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315d919b-2c25-46c6-ac8b-f76f24f677e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cat': 2, 'dog': 1, 'bird': 1})\n"
     ]
    }
   ],
   "source": [
    "text = \"cat dog cat bird\".split()\n",
    "print(Counter(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afe1170-d081-4049-8516-58065bb61097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'hello': 2, 'are': 2, 'you': 2, 'fine': 2, 'how': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "text = \"Hello, hello! How are you? Are you fine? Fine.\"\n",
    "\n",
    "# Step 1: Remove punctuation using regex\n",
    "cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Step 2: Convert to lowercase and split into words\n",
    "words = cleaned_text.lower().split()\n",
    "\n",
    "# Step 3: Count word frequency\n",
    "count = Counter(words)\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10253940-15bb-44b9-ad82-bf0efafe8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "# creating of random dictionary\n",
    "\n",
    "Record = {\n",
    "    'name' : 'Majid Hussain',\n",
    "    'roll_no': 1149,\n",
    "    'Section' : '3M(c)',\n",
    "    'subject':{\n",
    "        'AI' : \"ma'am maria sadiq\",\n",
    "        'DAA' : 'Muhammad Ahsen',\n",
    "        'Web DD': 'Muhammad waqas shareef',\n",
    "        'number':{\n",
    "            'math' : 30,\n",
    "            'ai' : 80,\n",
    "            'science' : 90\n",
    "    }\n",
    "    }\n",
    "}\n",
    "print(Record['subject']['number']['ai'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79d9b3a4-e166-47e2-9a8a-4cda8a301966",
   "metadata": {},
   "outputs": [],
   "source": [
    "Record['subject']['number']['computer'] = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b6f5784-5a89-466b-9224-75d0c2ad86d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Majid Hussain',\n",
       " 'roll_no': 1149,\n",
       " 'Section': '3M(c)',\n",
       " 'subject': {'AI': \"ma'am maria sadiq\",\n",
       "  'DAA': 'Muhammad Ahsen',\n",
       "  'Web DD': 'Muhammad waqas shareef',\n",
       "  'number': {'math': 30, 'ai': 85, 'science': 90, 'computer': 88}}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8956fa87-4732-4ac8-9ba2-c7c49b54adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "num = num*2\n",
    "num = num + num - 5\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988f49b-f2bc-456c-bbc3-2efb31d27fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6334b1e2-684f-4bdc-b919-88251afa6fb8",
   "metadata": {},
   "source": [
    "## Practice Exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6acf48f0-1d47-4ad4-bc8f-776798e80c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 'a small animal', 'table': ['a piece of furniture', 'a list of facts and figures']}\n"
     ]
    }
   ],
   "source": [
    "# Practice questions 1\n",
    "dictionary={\n",
    "    \"cat\": \"a small animal\",\n",
    "    \"table\":[\"a piece of furniture\", \"a list of facts and figures\"]\n",
    "}\n",
    "\n",
    "print(dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0abd1862-e8b3-4514-aeeb-2e461e27a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter First Movie Name:  Sanam Tery qasam\n",
      "Enter Second Movie Name:  Shadi mein zaroor ana \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'First Movie': 'Sanam Tery qasam', 'Second Movie': 'Shadi mein zaroor ana '}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sets = {}\n",
    "movie1 = str(input(\"Enter movie name :\"))\n",
    "sets.update({\"First Movie \": movie1})\n",
    "movie2 = str(input(\"Enter movie name :\"))\n",
    "sets.update({\"Second Movie \":movie2})\n",
    "print(sets)\n",
    "\"\"\"\n",
    "# like above I can also write short and efficient code\n",
    "titles = ['First Movie', 'Second Movie']\n",
    "movies = {title: input(f'Enter {title} Name: ') for title in titles}\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2943b78-a2f3-411a-8543-695351caa44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Enter Physices marks:  88\n",
      " Enter Chemistry marks:  78\n",
      " Enter Biology marks:  89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Physices': '88', 'Chemistry': '78', 'Biology': '89'}\n"
     ]
    }
   ],
   "source": [
    "# practice 4: WAP In which enter marks of 3 subject by the user and stored them in a dictionary first take empty dictionary and then store marks one by one\n",
    "\"\"\"\n",
    "dictionary= { }\n",
    "marks=int(input(\"enter physics:\"))\n",
    "dictionary.update({\"physics\":marks})\n",
    "\n",
    "marks=int(input(\"enter chemistery:\"))\n",
    "dictionary.update({\"chemistry\":marks})\n",
    "\n",
    "marks=int(input(\"enter Biology:\"))\n",
    "dictionary.update({\"Biology\":marks})\n",
    "print(dictionary)\n",
    "\"\"\" \n",
    "\n",
    "subjects = [ 'Physices' , 'Chemistry' , 'Biology']\n",
    "marks = {subject: input(f' Enter {subject} marks: ') for subject in subjects}\n",
    "print(marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1993e460-309f-4443-8e6f-3b7ba9a0e622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81, 10: 100}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. print first 10 numbers and their square\n",
    "{ i : i**2 for i in range(1, 11)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "675f6684-48a5-4b4b-a400-dfb006dc2783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('rajanpur', 390), ('multan', 90), ('lahore', 433), ('islamabad', 590), ('karachi', 802)])\n"
     ]
    }
   ],
   "source": [
    "# Q2. Distance of each city\n",
    "distances = { 'rajanpur' : 390 , 'multan' : 90, 'lahore' : 433 ,'islamabad' : 590, 'karachi' : 802}\n",
    "print(distances.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0caf987-7b9b-4677-a3fb-151bcf8e5c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rajanpur': 234.0,\n",
       " 'multan': 54.0,\n",
       " 'lahore': 259.8,\n",
       " 'islamabad': 354.0,\n",
       " 'karachi': 481.2}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using of given dictionary convert km to m\n",
    "distances = { 'rajanpur' : 390 , 'multan' : 90, 'lahore' : 433 ,'islamabad' : 590, 'karachi' : 802}\n",
    "{ key : values*0.6 for (key, values) in distances.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1d48d53-a442-4123-9675-b83018450b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sunday': 34.3,\n",
       " 'monday': 33.22,\n",
       " 'tuesday': 45.3,\n",
       " 'wednessday': 34.2,\n",
       " 'thursday': 12.4,\n",
       " 'friday': 1.1,\n",
       " 'saturday': 49.2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using of zip\n",
    "days = [ 'sunday', 'monday' , 'tuesday' , 'wednessday', 'thursday' , 'friday' , 'saturday' ]\n",
    "temp_c = [ 34.3 , 33.22, 45.3 , 34.2 , 12.4 , 1.1 , 49.2 ]\n",
    "{ key : value for (key, value) in zip(days, temp_c) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22dc330b-cd66-42a5-be44-1b9d2a367195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'laptop': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print of those items those stock is 0\n",
    "products = { 'iphone' : 210 , 'android' : 39 , 'laptop' : 0 , 'tablet' : 53}\n",
    "{ key : value for (key, value) in products.items() if value == 0}\n",
    "\n",
    "# Here is laptop is print because of stock is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef2c4e-cfc7-4d4b-9b2f-bcce09a71af1",
   "metadata": {},
   "source": [
    "## python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4758fa91-1a7e-4431-81a5-44c6f34ba2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   December 2012\n",
      "Mo Tu We Th Fr Sa Su\n",
      "                1  2\n",
      " 3  4  5  6  7  8  9\n",
      "10 11 12 13 14 15 16\n",
      "17 18 19 20 21 22 23\n",
      "24 25 26 27 28 29 30\n",
      "31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "yy = 2012\n",
    "mm = 12\n",
    "print(calendar.month(yy,mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab56c2e-2d14-4ab7-91ed-b99a470df555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.comb(5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ba0330-e29e-42c9-819b-e4105c823fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 55.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time.sleep(55)\n",
    "count_time = time.time() - start\n",
    "print(f\"Elapsed time: {count_time:.2f} seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e66e33-af36-4317-8ff1-9ce153698c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c', 'd')\n",
      "('a', 'b', 'd', 'c')\n",
      "('a', 'c', 'b', 'd')\n",
      "('a', 'c', 'd', 'b')\n",
      "('a', 'd', 'b', 'c')\n",
      "('a', 'd', 'c', 'b')\n",
      "('b', 'a', 'c', 'd')\n",
      "('b', 'a', 'd', 'c')\n",
      "('b', 'c', 'a', 'd')\n",
      "('b', 'c', 'd', 'a')\n",
      "('b', 'd', 'a', 'c')\n",
      "('b', 'd', 'c', 'a')\n",
      "('c', 'a', 'b', 'd')\n",
      "('c', 'a', 'd', 'b')\n",
      "('c', 'b', 'a', 'd')\n",
      "('c', 'b', 'd', 'a')\n",
      "('c', 'd', 'a', 'b')\n",
      "('c', 'd', 'b', 'a')\n",
      "('d', 'a', 'b', 'c')\n",
      "('d', 'a', 'c', 'b')\n",
      "('d', 'b', 'a', 'c')\n",
      "('d', 'b', 'c', 'a')\n",
      "('d', 'c', 'a', 'b')\n",
      "('d', 'c', 'b', 'a')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for i in itertools.permutations(['a', 'b', 'c', 'd']):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8075f74d-f860-42da-a9c3-f36d02cc1e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cat': 2, 'dog': 1, 'bird': 1})\n"
     ]
    }
   ],
   "source": [
    "# Counter ek dictionary type object banata hai jo har element ka frequency (count) store karta hai\n",
    "\n",
    "from collections import Counter\n",
    "text = \"cat dog cat bird\"\n",
    "freq = Counter(text.split())\n",
    "print(freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d4e1ed-73a7-48e1-94b1-f84bfbf411ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 2, 'dog': 1, 'bird': 1}\n"
     ]
    }
   ],
   "source": [
    "# for this efficient code is below you can also you this\n",
    "\n",
    "text = \"cat dog cat bird\"\n",
    "words = text.split()\n",
    "freq = {}\n",
    "for word in words:\n",
    "    freq[word] = freq.get(word, 0) + 1\n",
    "print(freq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb0b9717-3982-4978-b831-0226607bd3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'hello': 2, 'are': 2, 'you': 2, 'fine': 2, 'how': 1})\n"
     ]
    }
   ],
   "source": [
    "# clean paragraph and count word frequency\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "text = \"Hello, hello! How are you? Are you fine? Fine.\"\n",
    "clean_text = re.sub(r'[^\\w\\s]', ' ' , text)\n",
    "words = clean_text.lower().split()\n",
    "count = Counter(words)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4999129-4e04-46d3-b063-4a8c3e57fc6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please wait a moment while I gather a list of all available modules...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\pkgutil.py:78: UserWarning: The numpy.array_api submodule is still experimental. See NEP 47.\n",
      "  __import__(info.name)\n",
      "[2025-09-19 19:54:28,017] No QCoreApplication instance found. Application patches not applied. You have to call load_stylesheet function after instantiation of QApplication to take effect. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7f0197f6d050da244d93__mypyc commctrl            mdit_py_plugins     snappy\n",
      "IPython             compileall          mdurl               sndhdr\n",
      "OpenSSL             concurrent          menuinst            sniffio\n",
      "PIL                 conda               mimetypes           snowballstemmer\n",
      "PyQt5               conda_build         mistune             socket\n",
      "__future__          conda_content_trust mkl                 socketserver\n",
      "__hello__           conda_env           mkl_fft             socks\n",
      "__phello__          conda_index         mmap                sockshandler\n",
      "_abc                conda_libmamba_solver mmapfile            sortedcontainers\n",
      "_aix_support        conda_pack          mmsystem            soupsieve\n",
      "_argon2_cffi_bindings conda_package_handling modulefinder        sphinx\n",
      "_ast                conda_package_streaming more_itertools      spyder\n",
      "_asyncio            conda_token         mpmath              spyder_kernels\n",
      "_bisect             configparser        msgpack             sqlalchemy\n",
      "_black_version      constantly          msilib              sqlite3\n",
      "_blake2             contextlib          msvcrt              sre_compile\n",
      "_brotli             contextvars         multidict           sre_constants\n",
      "_bz2                contourpy           multipledispatch    sre_parse\n",
      "_cffi_backend       cookiecutter        multiprocessing     ssl\n",
      "_codecs             copy                mypy                sspi\n",
      "_codecs_cn          copyreg             mypy_extensions     sspicon\n",
      "_codecs_hk          cpuinfo             mypyc               stack_data\n",
      "_codecs_iso2022     crypt               nacl                stat\n",
      "_codecs_jp          cryptography        navigator_updater   statistics\n",
      "_codecs_kr          cssselect           nbclient            statsmodels\n",
      "_codecs_tw          csv                 nbconvert           streamlit\n",
      "_collections        ctypes              nbformat            string\n",
      "_collections_abc    curl                nest_asyncio        stringprep\n",
      "_compat_pickle      curses              netbios             struct\n",
      "_compression        cwp                 netrc               subprocess\n",
      "_contextvars        cycler              networkx            sunau\n",
      "_csv                cytoolz             nltk                sympy\n",
      "_ctypes             dask                nntplib             symtable\n",
      "_ctypes_test        dask_expr           notebook            sys\n",
      "_datetime           dataclasses         notebook_shim       sysconfig\n",
      "_decimal            datashader          nt                  tables\n",
      "_distutils_hack     datetime            ntpath              tabnanny\n",
      "_elementtree        dateutil            ntsecuritycon       tabulate\n",
      "_functools          dbi                 nturl2path          tarfile\n",
      "_hashlib            dbm                 numba               tblib\n",
      "_heapq              dde                 numbergen           telnetlib\n",
      "_imp                debugpy             numbers             tempfile\n",
      "_io                 decimal             numexpr             tenacity\n",
      "_json               decorator           numpy               terminado\n",
      "_locale             defusedxml          numpydoc            test\n",
      "_lsprof             diff_match_patch    odbc                test_pycosat\n",
      "_lzma               difflib             opcode              text_unidecode\n",
      "_markupbase         dill                openai              textdistance\n",
      "_md5                dis                 openpyxl            textwrap\n",
      "_msi                distributed         operator            this\n",
      "_multibytecodec     distro              optparse            threading\n",
      "_multiprocessing    docstring_to_markdown os                  threadpoolctl\n",
      "_nsis               doctest             overrides           three_merge\n",
      "_opcode             docutils            packaging           tifffile\n",
      "_operator           dotenv              pandas              time\n",
      "_osx_support        email               pandocfilters       timeit\n",
      "_overlapped         encodings           panel               timer\n",
      "_pickle             ensurepip           param               tinycss2\n",
      "_plotly_future_     entrypoints         paramiko            tkinter\n",
      "_plotly_utils       enum                parsel              tldextract\n",
      "_py_abc             erfa                parso               tlz\n",
      "_pydatetime         errno               partd               token\n",
      "_pydecimal          et_xmlfile          pathlib             tokenize\n",
      "_pyio               executing           pathspec            toml\n",
      "_pylong             fastjsonschema      patsy               tomli\n",
      "_pytest             faulthandler        pdb                 tomlkit\n",
      "_queue              filecmp             perfmon             tomllib\n",
      "_random             fileinput           pexpect             toolz\n",
      "_sha1               filelock            pickle              tornado\n",
      "_sha2               flake8              pickleshare         tqdm\n",
      "_sha3               flask               pickletools         trace\n",
      "_signal             fnmatch             pip                 traceback\n",
      "_sitebuiltins       fontTools           pipes               tracemalloc\n",
      "_socket             fqdn                pkce                traitlets\n",
      "_sqlite3            fractions           pkg_resources       truststore\n",
      "_sre                frozendict          pkginfo             tty\n",
      "_ssl                frozenlist          pkgutil             turtle\n",
      "_stat               fsspec              platform            turtledemo\n",
      "_statistics         ftplib              platformdirs        twisted\n",
      "_string             functools           plistlib            types\n",
      "_strptime           gc                  plotly              typing\n",
      "_struct             genericpath         pluggy              typing_extensions\n",
      "_symtable           gensim              ply                 tzdata\n",
      "_system_path        getopt              poplib              uc_micro\n",
      "_testbuffer         getpass             posixpath           ujson\n",
      "_testcapi           gettext             pprint              unicodedata\n",
      "_testclinic         git                 profile             unicodedata2\n",
      "_testconsole        gitdb               prometheus_client   unidecode\n",
      "_testimportmultiple glob                prompt_toolkit      unittest\n",
      "_testinternalcapi   graphlib            protego             uri_template\n",
      "_testmultiphase     greenlet            pstats              urllib\n",
      "_testsinglephase    gzip                psutil              urllib3\n",
      "_thread             h11                 pty                 uu\n",
      "_threading_local    h5py                ptyprocess          uuid\n",
      "_tkinter            hashlib             pure_eval           venv\n",
      "_tokenize           heapdict            py                  w3lib\n",
      "_tracemalloc        heapq               py_compile          warnings\n",
      "_typing             hmac                pyarrow             watchdog\n",
      "_uuid               holoviews           pyasn1              wave\n",
      "_warnings           html                pyasn1_modules      wcwidth\n",
      "_weakref            http                pyclbr              weakref\n",
      "_weakrefset         httpcore            pycodestyle         webbrowser\n",
      "_win32sysloader     httpx               pycosat             webcolors\n",
      "_winapi             hvplot              pycparser           webencodings\n",
      "_winxptheme         hyperlink           pyct                websocket\n",
      "_wmi                idlelib             pycurl              werkzeug\n",
      "_xxinterpchannels   idna                pydantic            whatthepatch\n",
      "_xxsubinterpreters  imagecodecs         pydantic_core       wheel\n",
      "_yaml               imageio             pydeck              widgetsnbextension\n",
      "_zoneinfo           imagesize           pydispatch          win2kras\n",
      "abc                 imaplib             pydoc               win32api\n",
      "adodbapi            imblearn            pydoc_data          win32clipboard\n",
      "afxres              imghdr              pydocstyle          win32com\n",
      "aifc                importlib           pyexpat             win32con\n",
      "aiobotocore         importlib_metadata  pyflakes            win32console\n",
      "aiohttp             incremental         pygments            win32cred\n",
      "aioitertools        inflection          pylab               win32crypt\n",
      "aiosignal           iniconfig           pylint              win32cryptcon\n",
      "alabaster           inspect             pylint_venv         win32ctypes\n",
      "altair              intake              pyls_spyder         win32event\n",
      "anaconda_anon_usage intervaltree        pylsp               win32evtlog\n",
      "anaconda_catalogs   io                  pylsp_black         win32evtlogutil\n",
      "anaconda_cloud_auth ipaddress           pylsp_jsonrpc       win32file\n",
      "anaconda_navigator  ipykernel           pyodbc              win32gui\n",
      "anaconda_project    ipykernel_launcher  pyparsing           win32gui_struct\n",
      "annotated_types     ipython_genutils    pytest              win32help\n",
      "antigravity         ipywidgets          pythoncom           win32inet\n",
      "anyio               isapi               pythonjsonlogger    win32inetcon\n",
      "appdirs             isoduration         pytoolconfig        win32job\n",
      "archspec            isort               pytz                win32lz\n",
      "argon2              isympy              pyviz_comms         win32net\n",
      "argparse            itemadapter         pywin               win32netcon\n",
      "array               itemloaders         pywin32_bootstrap   win32pdh\n",
      "arrow               itertools           pywin32_testutil    win32pdhquery\n",
      "ast                 itsdangerous        pywintypes          win32pdhutil\n",
      "astroid             jedi                pywt                win32pipe\n",
      "astropy             jellyfish           qdarkstyle          win32print\n",
      "astropy_iers_data   jinja2              qstylizer           win32process\n",
      "asttokens           jiter               qtawesome           win32profile\n",
      "async_lru           jmespath            qtconsole           win32ras\n",
      "asyncio             joblib              qtpy                win32rcparser\n",
      "atexit              json                queue               win32security\n",
      "atomicwrites        json5               queuelib            win32service\n",
      "attr                jsonpatch           quopri              win32serviceutil\n",
      "attrs               jsonpointer         random              win32timezone\n",
      "audioop             jsonschema          rasutil             win32trace\n",
      "automat             jsonschema_specifications re                  win32traceutil\n",
      "autopep8            jupyter             referencing         win32transaction\n",
      "babel               jupyter_client      regcheck            win32ts\n",
      "base64              jupyter_console     regex               win32ui\n",
      "bcrypt              jupyter_core        regutil             win32uiole\n",
      "bdb                 jupyter_events      repo_cli            win32verstamp\n",
      "binaryornot         jupyter_lsp         reprlib             win32wnet\n",
      "binascii            jupyter_server      requests            win_inet_pton\n",
      "binstar_client      jupyter_server_terminals requests_file       winerror\n",
      "bisect              jupyterlab          requests_toolbelt   winioctlcon\n",
      "black               jupyterlab_plotly   rfc3339_validator   winnt\n",
      "blackd              jupyterlab_pygments rfc3986_validator   winperf\n",
      "bleach              jupyterlab_server   rich                winpty\n",
      "blib2to3            jupyterlab_widgets  rlcompleter         winreg\n",
      "blinker             jwt                 rope                winsound\n",
      "bokeh               keyring             rpds                winxpgui\n",
      "boltons             keyword             rtree               winxptheme\n",
      "botocore            kiwisolver          ruamel_yaml         wrapt\n",
      "bottleneck          lazy_loader         runpy               wsgiref\n",
      "brotli              lazy_object_proxy   s3fs                xarray\n",
      "bs4                 lckr_jupyterlab_variableinspector sched               xdrlib\n",
      "builtins            lib2to3             scipy               xlwings\n",
      "bz2                 libarchive          scrapy              xlwingsjs\n",
      "cProfile            libmambapy          seaborn             xml\n",
      "cachetools          lief                secrets             xmlrpc\n",
      "calendar            linecache           select              xxlimited\n",
      "certifi             linkify_it          selectors           xxlimited_35\n",
      "cffi                llvmlite            semver              xxsubtype\n",
      "cgi                 lmdb                send2trash          xyzservices\n",
      "cgitb               locale              service_identity    yaml\n",
      "chardet             locket              servicemanager      yapf\n",
      "charset_normalizer  logging             setuptools          yapf_third_party\n",
      "chunk               lxml                shelve              yapftests\n",
      "click               lz4                 shlex               yarl\n",
      "cloudpickle         lzma                shutil              zict\n",
      "cmath               mailbox             signal              zipapp\n",
      "cmd                 mailcap             sipbuild            zipfile\n",
      "code                markdown            site                zipimport\n",
      "codecs              markdown_it         six                 zipp\n",
      "codeop              markupsafe          skimage             zlib\n",
      "collections         marshal             sklearn             zmq\n",
      "colorama            math                slugify             zoneinfo\n",
      "colorcet            matplotlib          smart_open          zope\n",
      "colorsys            matplotlib_inline   smmap               zstandard\n",
      "comm                mccabe              smtplib             \n",
      "\n",
      "Enter any module name to get more help.  Or, type \"modules spam\" to search\n",
      "for modules whose name or summary contain the string \"spam\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62335bbf-1485-43e8-8ae2-6321472c860f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk:\n",
      "\n",
      "NAME\n",
      "    nltk\n",
      "\n",
      "DESCRIPTION\n",
      "    The Natural Language Toolkit (NLTK) is an open source Python library\n",
      "    for Natural Language Processing.  A free online book is available.\n",
      "    (If you use the library for academic research, please cite the book.)\n",
      "\n",
      "    Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
      "    Natural Language Processing with Python.  O'Reilly Media Inc.\n",
      "    https://www.nltk.org/book/\n",
      "\n",
      "    isort:skip_file\n",
      "\n",
      "    @version: 3.8.1\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    app (package)\n",
      "    book\n",
      "    ccg (package)\n",
      "    chat (package)\n",
      "    chunk (package)\n",
      "    classify (package)\n",
      "    cli\n",
      "    cluster (package)\n",
      "    collections\n",
      "    collocations\n",
      "    compat\n",
      "    corpus (package)\n",
      "    data\n",
      "    decorators\n",
      "    downloader\n",
      "    draw (package)\n",
      "    featstruct\n",
      "    grammar\n",
      "    help\n",
      "    inference (package)\n",
      "    internals\n",
      "    jsontags\n",
      "    langnames\n",
      "    lazyimport\n",
      "    lm (package)\n",
      "    metrics (package)\n",
      "    misc (package)\n",
      "    parse (package)\n",
      "    probability\n",
      "    sem (package)\n",
      "    sentiment (package)\n",
      "    stem (package)\n",
      "    tag (package)\n",
      "    tbl (package)\n",
      "    test (package)\n",
      "    text\n",
      "    tgrep\n",
      "    tokenize (package)\n",
      "    toolbox\n",
      "    translate (package)\n",
      "    tree (package)\n",
      "    treeprettyprinter\n",
      "    treetransforms\n",
      "    twitter (package)\n",
      "    util\n",
      "    wsd\n",
      "\n",
      "SUBMODULES\n",
      "    agreement\n",
      "    aline\n",
      "    api\n",
      "    arlstem\n",
      "    arlstem2\n",
      "    association\n",
      "    bleu_score\n",
      "    bllip\n",
      "    boxer\n",
      "    brill\n",
      "    brill_trainer\n",
      "    casual\n",
      "    chart\n",
      "    chrf_score\n",
      "    cistem\n",
      "    confusionmatrix\n",
      "    corenlp\n",
      "    crf\n",
      "    decisiontree\n",
      "    dependencygraph\n",
      "    destructive\n",
      "    discourse\n",
      "    distance\n",
      "    drt\n",
      "    earleychart\n",
      "    evaluate\n",
      "    featurechart\n",
      "    gale_church\n",
      "    gdfa\n",
      "    gleu_score\n",
      "    glue\n",
      "    hmm\n",
      "    hunpos\n",
      "    ibm1\n",
      "    ibm2\n",
      "    ibm3\n",
      "    ibm4\n",
      "    ibm5\n",
      "    ibm_model\n",
      "    isri\n",
      "    lancaster\n",
      "    legality_principle\n",
      "    lfg\n",
      "    linearlogic\n",
      "    logic\n",
      "    mace\n",
      "    malt\n",
      "    mapping\n",
      "    maxent\n",
      "    megam\n",
      "    meteor_score\n",
      "    mwe\n",
      "    naivebayes\n",
      "    nist_score\n",
      "    nonprojectivedependencyparser\n",
      "    paice\n",
      "    pchart\n",
      "    perceptron\n",
      "    phrase_based\n",
      "    porter\n",
      "    positivenaivebayes\n",
      "    projectivedependencyparser\n",
      "    prover9\n",
      "    punkt\n",
      "    recursivedescent\n",
      "    regexp\n",
      "    relextract\n",
      "    repp\n",
      "    resolution\n",
      "    ribes_score\n",
      "    rslp\n",
      "    rte_classify\n",
      "    scikitlearn\n",
      "    scores\n",
      "    segmentation\n",
      "    senna\n",
      "    sequential\n",
      "    sexpr\n",
      "    shiftreduce\n",
      "    simple\n",
      "    snowball\n",
      "    sonority_sequencing\n",
      "    spearman\n",
      "    stack_decoder\n",
      "    stanford\n",
      "    stanford_segmenter\n",
      "    tableau\n",
      "    tadm\n",
      "    textcat\n",
      "    texttiling\n",
      "    tnt\n",
      "    toktok\n",
      "    transitionparser\n",
      "    treebank\n",
      "    viterbi\n",
      "    weka\n",
      "    wordnet\n",
      "\n",
      "FUNCTIONS\n",
      "    demo()\n",
      "        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n",
      "\n",
      "    tee(iterable, n=2, /)\n",
      "        Returns a tuple of n independent iterators.\n",
      "\n",
      "DATA\n",
      "    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n",
      "    SLASH = *slash*\n",
      "    TYPE = *type*\n",
      "    __author_email__ = 'nltk.team@gmail.com'\n",
      "    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n",
      "    __copyright__ = 'Copyright (C) 2001-2023 NLTK Project.\\n\\nDistribut......\n",
      "    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n",
      "    __license__ = 'Apache License, Version 2.0'\n",
      "    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...NL...\n",
      "    __maintainer__ = 'NLTK Team'\n",
      "    __maintainer_email__ = 'nltk.team@gmail.com'\n",
      "    __url__ = 'https://www.nltk.org/'\n",
      "    corpus = <LazyModule 'nltk.corpus'>\n",
      "    infile = <_io.TextIOWrapper name='C:\\\\Users\\\\Lenovo\\\\anac...kages\\\\nlt...\n",
      "    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n",
      "    toolbox = <LazyModule 'nltk.toolbox'>\n",
      "    version_file = r'C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\nltk\\VERS...\n",
      "\n",
      "VERSION\n",
      "    3.8.1\n",
      "\n",
      "AUTHOR\n",
      "    NLTK Team\n",
      "\n",
      "FILE\n",
      "    c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\nltk\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help('nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e346dd0-1118-4076-ad8b-bbeb46e3998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-19 22:51:24.124428\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today  = datetime.datetime.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51846b03-5025-4de9-a05f-7fefae200645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
